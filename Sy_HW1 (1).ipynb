{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cF_PdA69GAf5",
        "outputId": "cfde3345-1df7-4742-8408-e117827c068c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  label                                               text\n",
            "0   ham  Go until jurong point, crazy.. Available only ...\n",
            "1   ham                      Ok lar... Joking wif u oni...\n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3   ham  U dun say so early hor... U c already then say...\n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ],
      "source": [
        "import numpy as np # for mathematics\n",
        "import pandas as pd # for processing of data\n",
        "sh = pd.read_csv('spam.csv',encoding='latin-1')\n",
        "\n",
        "sh = sh.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1)\n",
        "sh = sh.rename(columns={\"v1\":'label', \"v2\":'text'})\n",
        "print(sh.head())\n",
        "tags = sh[\"label\"]\n",
        "texts = sh[\"message\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "MED7_r6YzGOE"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "jEVvzA1rzccz"
      },
      "outputs": [],
      "source": [
        "num_max = 1000\n",
        "le = LabelEncoder()\n",
        "tags = le.fit_transform(tags)\n",
        "tok = Tokenizer(num_words=num_max)\n",
        "tok.fit_on_texts(texts)\n",
        "mat_texts = tok.texts_to_matrix(texts,mode='count')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train,x_test,y_train,y_test = train_test_split(texts,tags, test_size = 0.3)\n",
        "mat_texts_tr = tok.texts_to_matrix(x_train,mode='count')\n",
        "mat_texts_tst = tok.texts_to_matrix(x_test,mode='count')\n",
        "\n",
        "max_len = 100\n",
        "x_train = tok.texts_to_sequences(x_train)\n",
        "x_test = tok.texts_to_sequences(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rrFnqm8tzlAw"
      },
      "outputs": [],
      "source": [
        "def get_simple_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512, activation='relu', input_shape=(num_max,)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc',metrics.binary_accuracy])\n",
        "    return (model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OzA6JiLXzqet"
      },
      "outputs": [],
      "source": [
        "def check_model(model,xtr,ytr,xts,yts):\n",
        "    model.fit(xtr,ytr,batch_size=32,epochs=10,verbose=1,validation_split=0.3)\n",
        "    print(' ')\n",
        "    model.evaluate(xts,yts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "oNSUmpLbvJoU"
      },
      "outputs": [],
      "source": [
        "def predict_model(model, x_test, y_test):\n",
        "    prediction = model.predict(x_test)\n",
        "    prediction = np.ceil(prediction)\n",
        "    accuracy = accuracy_score(prediction, y_test)\n",
        "    return accuracy\n",
        "\n",
        "def predict_model_output(model, x_test):\n",
        "    prediction = model.predict(x_test)\n",
        "    prediction = np.ceil(prediction)\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRPY9FC1ztkY",
        "outputId": "317f1812-3b42-4b38-d917-c8b5c602c9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 512)               512512    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 644,097\n",
            "Trainable params: 644,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 1s 8ms/step - loss: 0.2243 - acc: 0.9245 - binary_accuracy: 0.9245 - val_loss: 0.0869 - val_acc: 0.9863 - val_binary_accuracy: 0.9863\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0264 - acc: 0.9923 - binary_accuracy: 0.9923 - val_loss: 0.1012 - val_acc: 0.9855 - val_binary_accuracy: 0.9855\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.0090 - acc: 0.9978 - binary_accuracy: 0.9978 - val_loss: 0.1000 - val_acc: 0.9872 - val_binary_accuracy: 0.9872\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.0044 - acc: 0.9989 - binary_accuracy: 0.9989 - val_loss: 0.1189 - val_acc: 0.9863 - val_binary_accuracy: 0.9863\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.0038 - acc: 0.9993 - binary_accuracy: 0.9993 - val_loss: 0.1214 - val_acc: 0.9863 - val_binary_accuracy: 0.9863\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.0027 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1476 - val_acc: 0.9863 - val_binary_accuracy: 0.9863\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.0024 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1495 - val_acc: 0.9863 - val_binary_accuracy: 0.9863\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0023 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1532 - val_acc: 0.9863 - val_binary_accuracy: 0.9863\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1525 - val_acc: 0.9863 - val_binary_accuracy: 0.9863\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 1s 6ms/step - loss: 0.0018 - acc: 0.9996 - binary_accuracy: 0.9996 - val_loss: 0.1622 - val_acc: 0.9863 - val_binary_accuracy: 0.9863\n",
            " \n",
            "53/53 [==============================] - 0s 2ms/step - loss: 0.1371 - acc: 0.9862 - binary_accuracy: 0.9862\n"
          ]
        }
      ],
      "source": [
        "# for testing accuracy\n",
        "m = get_simple_model()\n",
        "check_model(m,mat_texts_tr,y_train,mat_texts_tst,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "uE47DPTGvJoe"
      },
      "outputs": [],
      "source": [
        "spam_test = pd.read_csv('output_spam.csv', encoding='latin-1')\n",
        "mat_texts_out = tok.texts_to_matrix(spam_test[\"text\"],mode='count')\n",
        "prediction_final = predict_model_output(m, mat_texts_out)\n",
        "prediction_test_out = pd.DataFrame(prediction_final, columns=['Text_type']).to_csv(\"output.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}